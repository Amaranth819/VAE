{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vae2.0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG7USkHb9-OA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorboardX\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs2xkrRj-AyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorboardX import SummaryWriter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJwRtjtK93FI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, nz = 32):\n",
        "        super(VAE, self).__init__()\n",
        "        self.nz = nz\n",
        "\n",
        "        self.encoder_fc = nn.Sequential(\n",
        "            nn.Linear(784, 256),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        self.mu_fc = nn.Linear(256, nz)\n",
        "        self.logvar_fc = nn.Linear(256, nz)\n",
        "        self.decoder_fc = nn.Sequential(\n",
        "            nn.Linear(nz, 256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, 784),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std, device = std.get_device(), requires_grad = True)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.encoder_fc(x)\n",
        "        return self.mu_fc(x), self.logvar_fc(x)\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder_fc(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        out = self.decode(z)\n",
        "        return out, mu, logvar\n",
        "\n",
        "def loss_func(recon_x, x, mu, logvar):\n",
        "    recon_loss = torch.sum(nn.MSELoss(reduction = 'none')(recon_x, x), dim = [1]) / x.size(0)\n",
        "    kl_divergence = torch.sum((mu.pow(2) + logvar.exp() - 1 - logvar) * 0.5, dim = [1]) / x.size(0)\n",
        "    return (recon_loss + kl_divergence).mean()\n",
        "\n",
        "def weight_init(net):\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            m.weight.data.uniform_(-0.1, 0.1)\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dSW0S0B-Ija",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mnist_dataset(dataset_path, bs, is_train):\n",
        "    return torch.utils.data.DataLoader(\n",
        "        torchvision.datasets.MNIST(\n",
        "            dataset_path, train = is_train,\n",
        "            download = True, transform = torchvision.transforms.ToTensor()\n",
        "        ),\n",
        "        batch_size = bs,\n",
        "        shuffle = True if is_train else False\n",
        "    )\n",
        "\n",
        "def train(config):\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    train_dataset = create_mnist_dataset(config['dataset_path'], config['batch_size'], True)\n",
        "    eval_dataset = create_mnist_dataset(config['dataset_path'], config['batch_size'], False)\n",
        "\n",
        "    net = VAE().to(device)\n",
        "    full_model_path = config['model_path'] + config['model_name']\n",
        "    if config['load_pretrained_model']:\n",
        "        net.load_state_dict(torch.load(full_model_path))\n",
        "        print('Load the pretrained model from %s successfully!' % full_model_path)\n",
        "    else:\n",
        "        weight_init(net)\n",
        "        if not os.path.exists(config['model_path']):\n",
        "            os.makedirs(config['model_path'])\n",
        "        print('First time training!')\n",
        "    net.train()\n",
        "    \n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr = config['learning_rate'], betas = [0.5, 0.999])\n",
        "\n",
        "    summary = SummaryWriter(config['summary_path'])\n",
        "    total_iter = 1\n",
        "\n",
        "    for e in range(1, config['epoch'] + 1):\n",
        "        for idx, (x, _) in enumerate(train_dataset):\n",
        "            x = x.to(device).view(-1, 784)\n",
        "            optimizer.zero_grad()\n",
        "            recon_x, mu, logvar = net(x)\n",
        "            loss = loss_func(recon_x, x, mu, logvar)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            print('[Epoch %d|Train Batch %d] Loss = %.6f' % (e, idx, loss.item()))\n",
        "            summary.add_scalar('Train/Loss', loss.item(), total_iter)\n",
        "            total_iter += 1\n",
        "\n",
        "        if e % 5 == 0:\n",
        "            net.eval()\n",
        "            eval_losses = []\n",
        "            with torch.no_grad():\n",
        "                for idx, (x, _) in enumerate(eval_dataset):\n",
        "                    x = x.to(device).view(-1, 784)\n",
        "                    recon_x, mu, logvar = net(x)\n",
        "                    loss = loss_func(recon_x, x, mu, logvar)\n",
        "                    \n",
        "                    print('[Epoch %d|Eval Batch %d] Loss = %.6f' % (e, idx, loss.item()))\n",
        "                    eval_losses.append(loss.item())\n",
        "\n",
        "                mean_eval_loss = np.mean(eval_losses)\n",
        "                summary.add_scalar('Eval/Loss', mean_eval_loss, e)\n",
        "            net.train()\n",
        "\n",
        "        if e % 5 == 0:\n",
        "            with torch.no_grad():\n",
        "                fake_z = torch.randn((64, net.nz)).to(device)\n",
        "                fake_imgs = net.decode(fake_z).view(-1, 1, 28, 28).detach()\n",
        "                fake_imgs = torchvision.utils.make_grid(fake_imgs, padding = 2, normalize = True).detach().cpu().numpy()\n",
        "                summary.add_image('Eval/Fake_imgs_after_%d_epochs' % e, fake_imgs, e)\n",
        "\n",
        "        if e % 2 == 0:\n",
        "            torch.save(net.state_dict(), full_model_path)\n",
        "\n",
        "    summary.close()\n",
        "\n",
        "def fake(config):\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    net = VAE().to(device)\n",
        "    net.load_state_dict((torch.load(config['model_path'] + config['model_name'])))\n",
        "    net.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake_z = torch.randn((64, net.nz)).to(device)\n",
        "        fake_imgs = net.decode(fake_z).view(-1, 1, 28, 28).detach()\n",
        "        plt.figure(figsize = (8, 8))\n",
        "        plt.axis('off')\n",
        "        plt.title('Fake images')\n",
        "        plt.imshow(np.transpose(torchvision.utils.make_grid(fake_imgs, padding = 2, normalize = True).cpu(), (1, 2, 0)))\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqqf5hUL-JJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = {\n",
        "    'is_train' : True,\n",
        "    'load_pretrained_model' : False,\n",
        "    'model_path' : './model/',\n",
        "    'model_name' : 'model.pkl',\n",
        "    'summary_path' : './summary/',\n",
        "    'dataset_path' : './data/',\n",
        "    'batch_size' : 128,\n",
        "    'epoch' : 30,\n",
        "    'learning_rate' : 1e-2\n",
        "}\n",
        "if config['is_train']:\n",
        "    train(config)\n",
        "else:\n",
        "    fake(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn06Xp5fCGnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(config['summary_path']))\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}